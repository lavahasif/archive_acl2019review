---
title : Effective Adversarial Regularization for Neural Machine Translation

---

In the field of natural language processing (NLP), the input is a sequence of discrete symbols, such as words or sentences. Since it is unreasonable to add a small perturbation to the symbols, applying the idea of adversarial training to NLP tasks has been recognized as a challenging problem. Recently, Miyato et al. (2017) overcame this problem and reported excellent performance improvements on multiple benchmark datasets of text classification task. The key idea of their success is to apply adversarial perturbations into the input embedding layer instead of the inputs themselves as used in image processing tasks. An important implication of their study is that their method can be interpreted as a regularization method, and thus, they do not focus on generating adversarial examples. We refer to this regularization technique as adversarial regularization.

Let $$r_i \in \mathbb{\mathit{R^D}}$$ be an adversarial perturbation vector for the i-th word in input X. The perturbed input embedding $$e_i \in \mathbb{\mathit{R^D}}$$ is computed for each encoder time-step i as follows:

$$e_i = E \times x_i + r_i$$

TODO: [이 페이퍼](https://openreview.net/pdf?id=r1X3g2_xl)에 text classification 에서의 adversarial regularization 이 나옴.